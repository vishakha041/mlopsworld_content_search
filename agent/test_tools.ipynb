{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baede1e7",
   "metadata": {},
   "source": [
    "# Manual Tool Testing for LangGraph Agent\n",
    "\n",
    "This notebook allows manual testing of all tools to verify they work correctly before using them in the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b863f9",
   "metadata": {},
   "source": [
    "## Setup: Load Environment and Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff63d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/ayesha/Projects/apertureDB Demo\n",
      "Added project root to sys.path\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path to ensure imports work\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get project root (parent of agent folder)\n",
    "project_root = Path.cwd().parent\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add to path if not already there\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(\"Added project root to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d5c619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env from: /Users/ayesha/Projects/apertureDB Demo/.env\n",
      ".env exists: True\n",
      "\n",
      "Environment variables loaded:\n",
      "  APERTUREDB_KEY: ✅ Set\n",
      "  GOOGLE_API_KEY: ✅ Set\n",
      "  APERTUREDB_KEY length: 128 chars\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env from project root\n",
    "env_path = project_root / \".env\"\n",
    "print(f\"Loading .env from: {env_path}\")\n",
    "print(f\".env exists: {env_path.exists()}\")\n",
    "\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Verify keys are loaded\n",
    "print(f\"\\nEnvironment variables loaded:\")\n",
    "print(f\"  APERTUREDB_KEY: {'✅ Set' if os.getenv('APERTUREDB_KEY') else '❌ Not set'}\")\n",
    "print(f\"  GOOGLE_API_KEY: {'✅ Set' if os.getenv('GOOGLE_API_KEY') else '❌ Not set'}\")\n",
    "print(f\"  APERTUREDB_KEY length: {len(os.getenv('APERTUREDB_KEY', ''))} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20d090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tools imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all tools\n",
    "from tools.tools import (\n",
    "    search_talks_by_filters,\n",
    "    search_talks_semantically,\n",
    "    analyze_speaker_activity,\n",
    "    get_talk_details,\n",
    "    find_similar_content,\n",
    "    analyze_topics_and_trends\n",
    ")\n",
    "\n",
    "print(\"✅ All tools imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43c80e",
   "metadata": {},
   "source": [
    "## Test 1: Search Talks by Filters (Top 5 Most Viewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fae13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: search_talks_by_filters\n",
      "Query: Top 5 most viewed talks\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/rnmpzv5s403_kckd36fzc8040000gn/T/ipykernel_62544/2830651348.py:5: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = search_talks_by_filters(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BaseTool.__call__() got an unexpected keyword argument 'limit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting: search_talks_by_filters\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuery: Top 5 most viewed talks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43msearch_talks_by_filters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort_by\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mviews\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort_order\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdesc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResult:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/apertureDB Demo/.venv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: BaseTool.__call__() got an unexpected keyword argument 'limit'"
     ]
    }
   ],
   "source": [
    "# Test the exact query the agent tried\n",
    "print(\"Testing: search_talks_by_filters\")\n",
    "print(\"Query: Top 5 most viewed talks\\n\")\n",
    "\n",
    "result = search_talks_by_filters(\n",
    "    limit=5,\n",
    "    sort_by=\"views\",\n",
    "    sort_order=\"desc\"\n",
    ")\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58308334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: search_talks_by_filters\n",
      "Query: Top 5 most viewed talks\n",
      "\n",
      "Result:\n",
      "{'results': [{'talk_id': 'f59b6283-69e7-5630-8789-4fe2bf0fca8c', 'title': 'Agentic AI: Unlocking Emergent Behavior in LLMs for Adaptive Workflow Automation', 'speaker': 'Patrick Marlow', 'company': 'Google', 'views': 2372, 'published_date': '2024-10-31', 'youtube_url': 'https://www.youtube.com/watch?v=GwQi33fmexU', 'event': 'TMLS 2024', 'category': 'Introduction to MLOps and GenAI', 'tech_level': 4, 'track': 'Applied Case Studies', 'abstract': 'Explore the emergent capabilities of \"agentic\" AI, where agents combine LLMs, reasoning loops, and tools to tackle complex workflows beyond the capabilities of LLMs alone. This session examines techni...'}, {'talk_id': '3bec210f-b106-5ff7-ab2c-3b467ff012d9', 'title': 'Optimizing AI/ML Workflows on Kubernetes: Advanced Techniques and Integration', 'speaker': 'Anu Reddy', 'company': 'Google', 'views': 26, 'published_date': '2024-12-11', 'youtube_url': 'https://www.youtube.com/watch?v=grCvM9tkS7Q', 'event': 'MLOps & GenAI World 2024', 'category': 'Deployment and integration', 'tech_level': 6, 'track': 'Advanced Technical/Research', 'abstract': \"Explore advanced technical strategies for optimizing AI/ML workflows on Kubernetes, the world's leading open-source container orchestration platform. This session will cover techniques for integrating...\"}, {'talk_id': '02f5e445-8821-5cb1-bada-88586b0f9ac8', 'title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'speaker': 'Nathan Beach', 'company': 'Google', 'views': 12, 'published_date': '2024-12-05', 'youtube_url': 'https://www.youtube.com/watch?v=5jdZksHaJ_Q', 'event': 'MLOps & GenAI World 2024', 'category': 'Performance optimization and efficiency', 'tech_level': 3, 'track': 'Research or Advanced Technical', 'abstract': 'When training or serving AI models, the cost of AI accelerators such as GPUs can dwarf the cost of all other compute resources combined.\\n\\nThis session provides techniques to leverage Kubernetes to ana...'}], 'total_found': 3, 'query_summary': \"Talks filtered by: company 'Google'\", 'sort_info': 'Sorted by views (highest first)', 'success': True}\n",
      "Result:\n",
      "{'results': [{'talk_id': 'f59b6283-69e7-5630-8789-4fe2bf0fca8c', 'title': 'Agentic AI: Unlocking Emergent Behavior in LLMs for Adaptive Workflow Automation', 'speaker': 'Patrick Marlow', 'company': 'Google', 'views': 2372, 'published_date': '2024-10-31', 'youtube_url': 'https://www.youtube.com/watch?v=GwQi33fmexU', 'event': 'TMLS 2024', 'category': 'Introduction to MLOps and GenAI', 'tech_level': 4, 'track': 'Applied Case Studies', 'abstract': 'Explore the emergent capabilities of \"agentic\" AI, where agents combine LLMs, reasoning loops, and tools to tackle complex workflows beyond the capabilities of LLMs alone. This session examines techni...'}, {'talk_id': '3bec210f-b106-5ff7-ab2c-3b467ff012d9', 'title': 'Optimizing AI/ML Workflows on Kubernetes: Advanced Techniques and Integration', 'speaker': 'Anu Reddy', 'company': 'Google', 'views': 26, 'published_date': '2024-12-11', 'youtube_url': 'https://www.youtube.com/watch?v=grCvM9tkS7Q', 'event': 'MLOps & GenAI World 2024', 'category': 'Deployment and integration', 'tech_level': 6, 'track': 'Advanced Technical/Research', 'abstract': \"Explore advanced technical strategies for optimizing AI/ML workflows on Kubernetes, the world's leading open-source container orchestration platform. This session will cover techniques for integrating...\"}, {'talk_id': '02f5e445-8821-5cb1-bada-88586b0f9ac8', 'title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'speaker': 'Nathan Beach', 'company': 'Google', 'views': 12, 'published_date': '2024-12-05', 'youtube_url': 'https://www.youtube.com/watch?v=5jdZksHaJ_Q', 'event': 'MLOps & GenAI World 2024', 'category': 'Performance optimization and efficiency', 'tech_level': 3, 'track': 'Research or Advanced Technical', 'abstract': 'When training or serving AI models, the cost of AI accelerators such as GPUs can dwarf the cost of all other compute resources combined.\\n\\nThis session provides techniques to leverage Kubernetes to ana...'}], 'total_found': 3, 'query_summary': \"Talks filtered by: company 'Google'\", 'sort_info': 'Sorted by views (highest first)', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test the exact query the agent tried\n",
    "print(\"Testing: search_talks_by_filters\")\n",
    "print(\"Query: Top 5 most viewed talks\\n\")\n",
    "\n",
    "result3 = search_talks_by_filters.invoke({\n",
    "    \"company_name\": \"Google\",\n",
    "    \"sort_by\": \"views\",\n",
    "    \"sort_order\": \"desc\",\n",
    "    \"limit\": 8\n",
    "})\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4214d4",
   "metadata": {},
   "source": [
    "## Test 2: Direct ApertureDB Connection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ApertureDB connection directly\n",
    "from tools.utils import get_db_connector\n",
    "\n",
    "print(\"Testing direct ApertureDB connection...\\n\")\n",
    "\n",
    "try:\n",
    "    con = get_db_connector()\n",
    "    print(\"✅ Connection successful!\\n\")\n",
    "    \n",
    "    # Try a simple query\n",
    "    print(\"Testing simple query: Count all Talk entities\\n\")\n",
    "    query = [{\n",
    "        \"FindEntity\": {\n",
    "            \"with_class\": \"Talk\",\n",
    "            \"results\": {\n",
    "                \"count\": True\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    "    \n",
    "    response = con.query(query)\n",
    "    print(\"Response:\")\n",
    "    print(response)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e847b0f",
   "metadata": {},
   "source": [
    "## Test 3: Query Top 5 Talks Directly with ApertureDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c92b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the exact query that search_talks_by_filters would generate\n",
    "from tools.utils import get_db_connector\n",
    "\n",
    "print(\"Testing: Direct ApertureDB query for top 5 most viewed talks\\n\")\n",
    "\n",
    "try:\n",
    "    con = get_db_connector()\n",
    "    \n",
    "    query = [{\n",
    "        \"FindEntity\": {\n",
    "            \"with_class\": \"Talk\",\n",
    "            \"constraints\": {\n",
    "                \"yt_views\": [\">=\", 0]  # Ensure yt_views exists\n",
    "            },\n",
    "            \"results\": {\n",
    "                \"all_properties\": True,\n",
    "                \"limit\": 5\n",
    "            },\n",
    "            \"sort\": {\n",
    "                \"key\": \"yt_views\",\n",
    "                \"order\": \"descending\"\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    "    \n",
    "    print(\"Query:\")\n",
    "    import json\n",
    "    print(json.dumps(query, indent=2))\n",
    "    print(\"\\nExecuting query...\\n\")\n",
    "    \n",
    "    response, _ = con.query(query)\n",
    "    \n",
    "    print(\"Response:\")\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "    # Extract and display talks\n",
    "    if response and len(response) > 0:\n",
    "        find_result = response[0].get('FindEntity', {})\n",
    "        entities = find_result.get('entities', [])\n",
    "        \n",
    "        if entities:\n",
    "            print(f\"\\n✅ Found {len(entities)} talks:\\n\")\n",
    "            for i, talk in enumerate(entities, 1):\n",
    "                title = talk.get('talk_title', 'N/A')\n",
    "                views = talk.get('yt_views', 'N/A')\n",
    "                speaker = talk.get('speaker_name', 'N/A')\n",
    "                print(f\"{i}. {title}\")\n",
    "                print(f\"   Speaker: {speaker}\")\n",
    "                print(f\"   Views: {views:,}\" if isinstance(views, int) else f\"   Views: {views}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"❌ No entities found in response\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834f9b7",
   "metadata": {},
   "source": [
    "## Test 4: Check Database Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af733afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what properties are available on Talk entities\n",
    "from tools.utils import get_db_connector\n",
    "\n",
    "print(\"Checking database schema...\\n\")\n",
    "\n",
    "try:\n",
    "    con = get_db_connector()\n",
    "    \n",
    "    query = [{\"GetSchema\": {}}]\n",
    "    response, _ = con.query(query)\n",
    "    \n",
    "    import json\n",
    "    print(\"Schema Response:\")\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b31ee4",
   "metadata": {},
   "source": [
    "## Test 5: Search Talks Semantically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic search\n",
    "print(\"Testing: search_talks_semantically\")\n",
    "print(\"Query: AI agents with memory\\n\")\n",
    "\n",
    "result = search_talks_semantically(\n",
    "    query=\"AI agents with memory\",\n",
    "    search_type=\"transcripts\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f51ab2",
   "metadata": {},
   "source": [
    "## Test 6: Get Talk Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get a talk title from the top viewed talks\n",
    "# Then test get_talk_details\n",
    "\n",
    "print(\"Testing: get_talk_details\\n\")\n",
    "\n",
    "# Use a known talk title (replace with actual title from Test 3 results)\n",
    "result = get_talk_details(\n",
    "    talk_title=\"Multimodal Agents You Can Deploy Anywhere\",  # Example\n",
    "    include_transcript=False\n",
    ")\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d387ae5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Run all cells above to test each tool individually and identify any issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
