{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb7iKfUhLZPD",
        "outputId": "e79666ee-96aa-4f51-8292-a8c896aaea1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for keepalive-socket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade aperturedb pandas python-dateutil tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "import re\n",
        "import pandas as pd\n",
        "from dateutil import parser as dtparser\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "from aperturedb.CommonLibrary import create_connector\n",
        "from aperturedb.ParallelLoader import ParallelLoader"
      ],
      "metadata": {
        "id": "VF7brv0TPhCm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ CONFIG ------------\n",
        "APERTUREDB_KEY = userdata.get('APERTUREDB_KEY')\n",
        "CSV_PATH = \"/content/mlops-events-enriched.csv\"\n",
        "\n",
        "ENTITY_CLASS = \"Talk\"  # entity class name in ApertureDB\n",
        "BATCHSIZE = 50\n",
        "NUMTHREADS = 8\n",
        "SHOW_STATS = True"
      ],
      "metadata": {
        "id": "4BKNa8QyPk6c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ HELPERS ------------\n",
        "\n",
        "def clean_str_or_none(v):\n",
        "    import pandas as pd\n",
        "    # If a Series sneaks in, take the first non-null scalar\n",
        "    if isinstance(v, pd.Series):\n",
        "        v = v.dropna()\n",
        "        v = v.iloc[0] if len(v) else None\n",
        "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
        "        return None\n",
        "    s = str(v).strip()\n",
        "    return s if s else None\n",
        "\n",
        "def coerce_int_or_none(v):\n",
        "    import pandas as pd, re\n",
        "    if isinstance(v, pd.Series):\n",
        "        v = v.dropna()\n",
        "        v = v.iloc[0] if len(v) else None\n",
        "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
        "        return None\n",
        "    s = str(v)\n",
        "    m = re.search(r\"\\d+\", s.replace(\",\", \"\"))\n",
        "    return int(m.group(0)) if m else None\n",
        "\n",
        "def to_aperturedb_date(value):\n",
        "    # Accepts things like \"Dec 5, 2024\" and returns \"2024-12-05\"\n",
        "    import pandas as pd\n",
        "    from dateutil import parser as dtparser\n",
        "    if isinstance(value, pd.Series):\n",
        "        value = value.dropna()\n",
        "        value = value.iloc[0] if len(value) else None\n",
        "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
        "        return None\n",
        "    try:\n",
        "        dt = dtparser.parse(str(value))\n",
        "        return dt.strftime(\"%Y-%m-%d\")  # <-- date only (no time, no T/Z)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def extract_youtube_id(url: str):\n",
        "    \"\"\"Try to get YouTube ID from either 'YouTube ID' column or 'YouTube Link' values.\"\"\"\n",
        "    if pd.isna(url):\n",
        "        return None\n",
        "    s = str(url).strip()\n",
        "    # common forms\n",
        "    m = re.search(r\"[?&]v=([A-Za-z0-9_-]{6,})\", s)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    m = re.search(r\"youtu\\.be/([A-Za-z0-9_-]{6,})\", s)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    return None\n",
        "\n",
        "def make_talk_id(talk_title: str, youtube_id: str):\n",
        "    \"\"\"\n",
        "    Deterministic UUID: reruns won't generate a new ID.\n",
        "    Uses UUID5 over a stable string (title + youtube_id).\n",
        "    \"\"\"\n",
        "    base = f\"{(talk_title or '').strip()}|{(youtube_id or '').strip()}\"\n",
        "    return str(uuid.uuid5(uuid.NAMESPACE_URL, base))\n"
      ],
      "metadata": {
        "id": "Uz9PHzaDP97E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ LOAD DATA ------------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Keep only rows with a talk title\n",
        "df = df[df[\"Talk Title\"].notna()].copy().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "drv6d0hVQWUR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TalksGenerator:\n",
        "    \"\"\"\n",
        "    ParallelLoader calls generator[start:stop] and expects\n",
        "    a *list* of (commands, blobs) pairs for slices.\n",
        "    For single int indices, a single (commands, blobs) pair is OK.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame):\n",
        "        # optional: remove duplicate column names defensively\n",
        "        self.df = dataframe.loc[:, ~dataframe.columns.duplicated()].copy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _row_to_cmd_blob(self, idx: int):\n",
        "        def get(col):\n",
        "            return self.df.at[idx, col] if col in self.df.columns else None\n",
        "\n",
        "        talk_title   = clean_str_or_none(get(\"Talk Title\"))\n",
        "        youtube_id_c = clean_str_or_none(get(\"YouTube ID\"))\n",
        "        youtube_url  = clean_str_or_none(get(\"YouTube Link\"))\n",
        "        youtube_id   = youtube_id_c or extract_youtube_id(youtube_url)\n",
        "\n",
        "        talk_id = make_talk_id(talk_title or \"\", youtube_id or \"\")\n",
        "\n",
        "        props = {\n",
        "            \"talk_id\": talk_id,\n",
        "            \"talk_title\": talk_title,\n",
        "        }\n",
        "        if youtube_id:  props[\"youtube_id\"]  = youtube_id\n",
        "        if youtube_url: props[\"youtube_url\"] = youtube_url\n",
        "\n",
        "        kw_csv = clean_str_or_none(get(\"Top 3 keywords (in order)\"))\n",
        "        if kw_csv is not None:\n",
        "            props[\"keywords_csv\"] = kw_csv\n",
        "\n",
        "        mapping = [\n",
        "            (\"Full Name\", \"speaker_name\"),\n",
        "            (\"Company Name\", \"company_name\"),\n",
        "            (\"Job Title\", \"job_title\"),\n",
        "            (\"Abstract\", \"abstract\"),\n",
        "            (\"What You'll Learn\", \"what_youll_learn\"),\n",
        "            (\"Prerequiste Knowledge (if required)\", \"prereq_knowledge\"),\n",
        "            (\"Track\", \"track\"),\n",
        "            (\"Category 1\", \"category_primary\"),\n",
        "            (\"Bio\", \"bio\"),\n",
        "            (\"Relevant Industries\", \"industries\"),\n",
        "            (\"What is Unique about your session\", \"unique_session_note\"),\n",
        "            (\"Event\", \"event_name\"),\n",
        "        ]\n",
        "        for csv_col, db_key in mapping:\n",
        "            val = clean_str_or_none(get(csv_col))\n",
        "            if val is not None:\n",
        "                props[db_key] = val\n",
        "\n",
        "        tech_level = coerce_int_or_none(get(\"Technical Level (1-7)\"))\n",
        "        if tech_level is not None:\n",
        "            props[\"tech_level\"] = tech_level\n",
        "\n",
        "        views = coerce_int_or_none(get(\"yt_views\"))\n",
        "        if views is not None:\n",
        "            props[\"yt_views\"] = views\n",
        "\n",
        "        iso_date = to_aperturedb_date(get(\"yt_published_date\"))\n",
        "        if iso_date is not None:\n",
        "            props[\"yt_published_at\"] = {\"_date\": iso_date}\n",
        "\n",
        "        cmd = {\n",
        "            \"AddEntity\": {\n",
        "                \"class\": ENTITY_CLASS,\n",
        "                \"if_not_found\": { \"talk_id\": [\"==\", talk_id] },\n",
        "                \"properties\": props\n",
        "            }\n",
        "        }\n",
        "        return [cmd], []  # (commands, blobs)\n",
        "\n",
        "    def __getitem__(self, idx_or_slice):\n",
        "        # Single index → one (commands, blobs) pair\n",
        "        if isinstance(idx_or_slice, int):\n",
        "            return self._row_to_cmd_blob(idx_or_slice)\n",
        "\n",
        "        # Slice → list of (commands, blobs) pairs\n",
        "        if isinstance(idx_or_slice, slice):\n",
        "            start = idx_or_slice.start or 0\n",
        "            stop  = idx_or_slice.stop  or len(self.df)\n",
        "            step  = idx_or_slice.step  or 1\n",
        "            out = []\n",
        "            for i in range(start, min(stop, len(self.df)), step):\n",
        "                out.append(self._row_to_cmd_blob(i))\n",
        "            return out\n",
        "\n",
        "        # Iterable of indices → list of pairs\n",
        "        try:\n",
        "            indices = list(idx_or_slice)\n",
        "            out = []\n",
        "            for i in indices:\n",
        "                out.append(self._row_to_cmd_blob(int(i)))\n",
        "            return out\n",
        "        except Exception:\n",
        "            # Fallback: treat as single index\n",
        "            return self._row_to_cmd_blob(int(idx_or_slice))\n",
        "\n",
        "    def get_indices(self):\n",
        "        # Let ParallelLoader.query_setup() auto-create this index\n",
        "        return { \"entity\": { ENTITY_CLASS: [\"talk_id\"] } }"
      ],
      "metadata": {
        "id": "3yJWx5fZQZC-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ CONNECT & INGEST ------------\n",
        "client = create_connector(key=APERTUREDB_KEY)\n",
        "loader = ParallelLoader(client)\n",
        "\n",
        "gen = TalksGenerator(df)\n",
        "\n",
        "# auto-create indices based on get_indices()\n",
        "loader.query_setup(gen)  # creates entity index on Talk.talk_id if missing\n",
        "\n",
        "# parallel, batched ingestion\n",
        "loader.ingest(gen, batchsize=BATCHSIZE, numthreads=NUMTHREADS, stats=SHOW_STATS)\n",
        "\n",
        "print(\"Done. Ingestion attempted for\", len(gen), \"rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZlZJgt7Qxt7",
        "outputId": "e47acdbd-e8b7-4a87-e4f8-cbddd0db0f53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 278/278 [00:03<00:00, 90.3items/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============ ApertureDB Loader Stats ============\n",
            "Total time (s): 3.080139636993408\n",
            "Total queries executed: 8\n",
            "Avg Query time (s): 1.9688595533370972\n",
            "Query time std: 0.19235428751942202\n",
            "Avg Query Throughput (q/s): 4.063265958427805\n",
            "Overall insertion throughput (element/s): 90.255648367735\n",
            "Total inserted elements: 278\n",
            "Total successful commands: 278\n",
            "=================================================\n",
            "Done. Ingestion attempted for 278 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity Check Queries"
      ],
      "metadata": {
        "id": "PlE1eaghbSiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(q):\n",
        "    resp, blobs = client.query(q)\n",
        "    client.print_last_response()\n",
        "    return resp"
      ],
      "metadata": {
        "id": "gPtXIvQbQ478"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Count all talks\n",
        "\n",
        "Confirms total inserts."
      ],
      "metadata": {
        "id": "bXzU0MkNUPiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([{\n",
        "  \"FindEntity\": {\n",
        "    \"with_class\": \"Talk\",\n",
        "    \"results\": { \"count\": True }\n",
        "  }\n",
        "}])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iByc7iCXUKzp",
        "outputId": "b40ad223-3a25-4bfe-91a2-005b1970cbb1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"count\": 278,\n",
            "            \"returned\": 0,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'count': 278, 'returned': 0, 'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Peek newest 5 by publish date\n",
        "\n",
        "Verifies date parsing + sorting"
      ],
      "metadata": {
        "id": "MPKoALCuUSCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([{\n",
        "  \"FindEntity\": {\n",
        "    \"with_class\": \"Talk\",\n",
        "    \"sort\": { \"key\": \"yt_published_at\", \"order\": \"descending\" },\n",
        "    \"limit\": 5,\n",
        "    \"results\": {\n",
        "      \"list\": [\"talk_id\", \"talk_title\", \"yt_published_at\", \"youtube_url\"]\n",
        "    }\n",
        "  }\n",
        "}])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbkwWscyUM5C",
        "outputId": "190064ee-c18b-4585-9ed7-953f0c0dc753"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"entities\": [\n",
            "                {\n",
            "                    \"talk_id\": \"b792c10c-776b-5e2d-bb2e-3f25ea29f330\",\n",
            "                    \"talk_title\": \"Building GenAI-Powered Apps: A Workshop for Software Engineers\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=tSIpREFVMXs\",\n",
            "                    \"yt_published_at\": {\n",
            "                        \"_date\": \"2025-02-13T00:00:00+00:00\"\n",
            "                    }\n",
            "                },\n",
            "                {\n",
            "                    \"talk_id\": \"36ad6014-7028-578d-800a-f969b7605df9\",\n",
            "                    \"talk_title\": \"LLMidas' Touch; Safely adopting GenAI for production use-cases\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=A3KschpEU_g\",\n",
            "                    \"yt_published_at\": {\n",
            "                        \"_date\": \"2025-01-14T00:00:00+00:00\"\n",
            "                    }\n",
            "                },\n",
            "                {\n",
            "                    \"talk_id\": \"3bec210f-b106-5ff7-ab2c-3b467ff012d9\",\n",
            "                    \"talk_title\": \"Optimizing AI/ML Workflows on Kubernetes: Advanced Techniques and Integration\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=grCvM9tkS7Q\",\n",
            "                    \"yt_published_at\": {\n",
            "                        \"_date\": \"2024-12-11T00:00:00+00:00\"\n",
            "                    }\n",
            "                },\n",
            "                {\n",
            "                    \"talk_id\": \"970e274c-873e-5059-aac0-87bb02b38e98\",\n",
            "                    \"talk_title\": \"Revolutionizing the skies: Mlops case study of LATAM airlines\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=h6X7Cbo_-ho\",\n",
            "                    \"yt_published_at\": {\n",
            "                        \"_date\": \"2024-12-11T00:00:00+00:00\"\n",
            "                    }\n",
            "                },\n",
            "                {\n",
            "                    \"talk_id\": \"4e0c7f79-d08a-5eed-8500-eda5faa5ec2f\",\n",
            "                    \"talk_title\": \"Panel: The Current Investment Landscape. Opportunities & Challenges in ML/Gen AI\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=V5k4Mpbd0h4\",\n",
            "                    \"yt_published_at\": {\n",
            "                        \"_date\": \"2024-12-11T00:00:00+00:00\"\n",
            "                    }\n",
            "                }\n",
            "            ],\n",
            "            \"returned\": 5,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'entities': [{'talk_id': 'b792c10c-776b-5e2d-bb2e-3f25ea29f330',\n",
              "     'talk_title': 'Building GenAI-Powered Apps: A Workshop for Software Engineers',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=tSIpREFVMXs',\n",
              "     'yt_published_at': {'_date': '2025-02-13T00:00:00+00:00'}},\n",
              "    {'talk_id': '36ad6014-7028-578d-800a-f969b7605df9',\n",
              "     'talk_title': \"LLMidas' Touch; Safely adopting GenAI for production use-cases\",\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=A3KschpEU_g',\n",
              "     'yt_published_at': {'_date': '2025-01-14T00:00:00+00:00'}},\n",
              "    {'talk_id': '3bec210f-b106-5ff7-ab2c-3b467ff012d9',\n",
              "     'talk_title': 'Optimizing AI/ML Workflows on Kubernetes: Advanced Techniques and Integration',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=grCvM9tkS7Q',\n",
              "     'yt_published_at': {'_date': '2024-12-11T00:00:00+00:00'}},\n",
              "    {'talk_id': '970e274c-873e-5059-aac0-87bb02b38e98',\n",
              "     'talk_title': 'Revolutionizing the skies: Mlops case study of LATAM airlines',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=h6X7Cbo_-ho',\n",
              "     'yt_published_at': {'_date': '2024-12-11T00:00:00+00:00'}},\n",
              "    {'talk_id': '4e0c7f79-d08a-5eed-8500-eda5faa5ec2f',\n",
              "     'talk_title': 'Panel: The Current Investment Landscape. Opportunities & Challenges in ML/Gen AI',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=V5k4Mpbd0h4',\n",
              "     'yt_published_at': {'_date': '2024-12-11T00:00:00+00:00'}}],\n",
              "   'returned': 5,\n",
              "   'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Spot-check a specific talk_id is unique\n",
        "\n",
        "Taking talk id one printed by #2."
      ],
      "metadata": {
        "id": "gInkxIiWUZRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([{\n",
        "  \"FindEntity\": {\n",
        "    \"with_class\": \"Talk\",\n",
        "    \"unique\": True,\n",
        "    \"constraints\": { \"talk_id\": [\"==\", \"970e274c-873e-5059-aac0-87bb02b38e98\"] },\n",
        "    \"results\": { \"all_properties\": True }\n",
        "  }\n",
        "}])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo8yZ_cJUTw0",
        "outputId": "8b49922d-165e-418a-9ea6-135710081bef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"entities\": [\n",
            "                {\n",
            "                    \"_uniqueid\": \"7.115.262\",\n",
            "                    \"abstract\": \"This talk explores how LATAM Airlines leveraged MLOps to revolutionize their operations and achieve financial gain in the hundred of millions of dollars. By integrating machine learning models into their daily workflows and automating the deployment and management processes, LATAM Airlines was able to optimize tariffs, enhance customer experiences, and streamline maintenance operations. The talk will highlight key MLOps strategies employed, such as continuous integration and delivery of ML models, real-time data processing. Attendees will gain insights into the tangible benefits of MLOps, including cost savings, operational efficiencies, and revenue growth, showcasing how strategic ML operations can create substantial value in the airline industry.\",\n",
            "                    \"bio\": \"Michael Haacke Concha is the Lead Machine Learning Engineer of the centralized MLOps team at LATAM Airlines. He holds both a Bachelor's and a Master\\u2019s degree in Theoretical Physics from Pontificia Universidad Cat\\u00f3lica de Chile (PUC). Over his three years at LATAM Airlines, he developed an archival and retrieval system for black box data of the aircraft to support analytics. He then played a key role in building the framework for integrating the Iguazio MLOps platform within the company. In the past year, he has been leading the development of a new platform using Vertex GCP.\\n\\nPrior to joining LATAM Airlines, Michael worked as a data scientist on the ATLAS experiment at the Large Hadron Collider (LHC), where he contributed to various studies, including the search for a long-lived Dark Photon and a Heavy Higgs.\\n\\nDiego Castillo is a Consultant Machine Learning Engineer at Neuralworks, currently on assignment as Staff in LATAM Airlines, where he plays a pivotal role within the decentralized Data & AI Operations team. A graduate of the University of Chile with a degree in Electrical Engineering, Diego has excelled in cross-functional roles, driving the seamless integration of machine learning models into large-scale production environments. As a Staff Machine Learning Engineer at LATAM, he not only leads and mentors other MLEs but also shapes the technical direction across key business areas.\\nThroughout his career at LATAM Airlines, Diego has significantly impacted diverse domains, including Cargo, Customer Care and the App and Landing Page teams. He has more recently been supporting the migration of the MLOPS internal framework from Iguazio to Vertex GCP.\\nWith a comprehensive expertise spanning the entire machine learning lifecycle, Diego brings a wealth of experience from previous roles, including Data Scientist, Backend Developer, and Data Engineer, making him a versatile leader in the AI space.\",\n",
            "                    \"category_primary\": \"Deployment and integration\",\n",
            "                    \"company_name\": \"LATAM Airlines\",\n",
            "                    \"event_name\": \"MLOps & GenAI World 2024\",\n",
            "                    \"job_title\": \"MLOps Lead, Staff Machine Learning Engineer\",\n",
            "                    \"keywords_csv\": \"MLOps, Operational efficiency, \\nAirline industry\",\n",
            "                    \"speaker_name\": \"Michael Haacke Concha, Diego Castillo Warnken\",\n",
            "                    \"talk_id\": \"970e274c-873e-5059-aac0-87bb02b38e98\",\n",
            "                    \"talk_title\": \"Revolutionizing the skies: Mlops case study of LATAM airlines\",\n",
            "                    \"tech_level\": 2,\n",
            "                    \"track\": \"Applied Case Studies\",\n",
            "                    \"unique_session_note\": \"Exclusive insight to use cases in the aviation industry, working with a inhouse MLOps ecosystem with more than 60 different products with current developments team of more of 100 developers.\",\n",
            "                    \"what_youll_learn\": \"You will acquire insight into how a scalable and decentralized tech team grows inside LATAM airlines, thanks to technology and organizational structure. also you will learn some of our successful use cases of our MLOps ecosystem.\",\n",
            "                    \"youtube_id\": \"h6X7Cbo_-ho\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=h6X7Cbo_-ho\",\n",
            "                    \"yt_published_at\": {\n",
            "                        \"_date\": \"2024-12-11T00:00:00+00:00\"\n",
            "                    },\n",
            "                    \"yt_views\": 74\n",
            "                }\n",
            "            ],\n",
            "            \"returned\": 1,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'entities': [{'_uniqueid': '7.115.262',\n",
              "     'abstract': 'This talk explores how LATAM Airlines leveraged MLOps to revolutionize their operations and achieve financial gain in the hundred of millions of dollars. By integrating machine learning models into their daily workflows and automating the deployment and management processes, LATAM Airlines was able to optimize tariffs, enhance customer experiences, and streamline maintenance operations. The talk will highlight key MLOps strategies employed, such as continuous integration and delivery of ML models, real-time data processing. Attendees will gain insights into the tangible benefits of MLOps, including cost savings, operational efficiencies, and revenue growth, showcasing how strategic ML operations can create substantial value in the airline industry.',\n",
              "     'bio': \"Michael Haacke Concha is the Lead Machine Learning Engineer of the centralized MLOps team at LATAM Airlines. He holds both a Bachelor's and a Master’s degree in Theoretical Physics from Pontificia Universidad Católica de Chile (PUC). Over his three years at LATAM Airlines, he developed an archival and retrieval system for black box data of the aircraft to support analytics. He then played a key role in building the framework for integrating the Iguazio MLOps platform within the company. In the past year, he has been leading the development of a new platform using Vertex GCP.\\n\\nPrior to joining LATAM Airlines, Michael worked as a data scientist on the ATLAS experiment at the Large Hadron Collider (LHC), where he contributed to various studies, including the search for a long-lived Dark Photon and a Heavy Higgs.\\n\\nDiego Castillo is a Consultant Machine Learning Engineer at Neuralworks, currently on assignment as Staff in LATAM Airlines, where he plays a pivotal role within the decentralized Data & AI Operations team. A graduate of the University of Chile with a degree in Electrical Engineering, Diego has excelled in cross-functional roles, driving the seamless integration of machine learning models into large-scale production environments. As a Staff Machine Learning Engineer at LATAM, he not only leads and mentors other MLEs but also shapes the technical direction across key business areas.\\nThroughout his career at LATAM Airlines, Diego has significantly impacted diverse domains, including Cargo, Customer Care and the App and Landing Page teams. He has more recently been supporting the migration of the MLOPS internal framework from Iguazio to Vertex GCP.\\nWith a comprehensive expertise spanning the entire machine learning lifecycle, Diego brings a wealth of experience from previous roles, including Data Scientist, Backend Developer, and Data Engineer, making him a versatile leader in the AI space.\",\n",
              "     'category_primary': 'Deployment and integration',\n",
              "     'company_name': 'LATAM Airlines',\n",
              "     'event_name': 'MLOps & GenAI World 2024',\n",
              "     'job_title': 'MLOps Lead, Staff Machine Learning Engineer',\n",
              "     'keywords_csv': 'MLOps, Operational efficiency, \\nAirline industry',\n",
              "     'speaker_name': 'Michael Haacke Concha, Diego Castillo Warnken',\n",
              "     'talk_id': '970e274c-873e-5059-aac0-87bb02b38e98',\n",
              "     'talk_title': 'Revolutionizing the skies: Mlops case study of LATAM airlines',\n",
              "     'tech_level': 2,\n",
              "     'track': 'Applied Case Studies',\n",
              "     'unique_session_note': 'Exclusive insight to use cases in the aviation industry, working with a inhouse MLOps ecosystem with more than 60 different products with current developments team of more of 100 developers.',\n",
              "     'what_youll_learn': 'You will acquire insight into how a scalable and decentralized tech team grows inside LATAM airlines, thanks to technology and organizational structure. also you will learn some of our successful use cases of our MLOps ecosystem.',\n",
              "     'youtube_id': 'h6X7Cbo_-ho',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=h6X7Cbo_-ho',\n",
              "     'yt_published_at': {'_date': '2024-12-11T00:00:00+00:00'},\n",
              "     'yt_views': 74}],\n",
              "   'returned': 1,\n",
              "   'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) How many talks in 2024?\n",
        "\n",
        "Date range filter with _date."
      ],
      "metadata": {
        "id": "2ZBjAhFtUosG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([{\n",
        "  \"FindEntity\": {\n",
        "    \"with_class\": \"Talk\",\n",
        "    \"constraints\": {\n",
        "      \"yt_published_at\": [\n",
        "        \">=\", {\"_date\": \"2024-01-01\"},\n",
        "        \"<=\", {\"_date\": \"2024-12-31\"}\n",
        "      ]\n",
        "    },\n",
        "    \"results\": { \"count\": True }\n",
        "  }\n",
        "}])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2M7OtW7UlVO",
        "outputId": "fc25c74f-2005-4893-a8e3-66c57b32117d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"count\": 149,\n",
            "            \"returned\": 0,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'count': 149, 'returned': 0, 'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Top 10 by views (descending)\n",
        "\n",
        "Check the numeric column yt_views."
      ],
      "metadata": {
        "id": "wRHrUGu_UtrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([{\n",
        "  \"FindEntity\": {\n",
        "    \"with_class\": \"Talk\",\n",
        "    \"constraints\": { \"yt_views\": [\">\", 0] },\n",
        "    \"sort\": { \"key\": \"yt_views\", \"order\": \"descending\" },\n",
        "    \"limit\": 10,\n",
        "    \"results\": { \"list\": [\"talk_title\", \"yt_views\", \"youtube_url\"] }\n",
        "  }\n",
        "}])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKkKjhIiUqF5",
        "outputId": "5a8c9514-3d92-44c5-db85-70788706ea99"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"entities\": [\n",
            "                {\n",
            "                    \"talk_title\": \"BloombergGPT: How we built a 50 billion parameter financial language model\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=m2Scj2SO85Y\",\n",
            "                    \"yt_views\": 127705\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"Quantifying the uncertainty in model predictions\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=-K8vDIyT3xY\",\n",
            "                    \"yt_views\": 4364\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"Building a Measurement System for Personalization: A Bayesian Approach\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=2DZogx96aR4\",\n",
            "                    \"yt_views\": 3755\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"Agentic AI: Unlocking Emergent Behavior in LLMs for Adaptive Workflow Automation\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=GwQi33fmexU\",\n",
            "                    \"yt_views\": 2372\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"Making ChatGPT funny with Prompt Optimization\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=lo6OOTlSS6A\",\n",
            "                    \"yt_views\": 2279\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"How many Labelled Examples do you need for a BERT-sized Model to Beat GPT4 on Predictive Tasks?\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=3iaxLTKJROc\",\n",
            "                    \"yt_views\": 1873\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"LLMs for Leaders & Senior Product Managers\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=RJawFx4kSMM\",\n",
            "                    \"yt_views\": 1666\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"Learn Your Codebase: Fine-tuning CodeLlama with Flyte\\u2026 to Learn Flyte\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=VjIVPmow31A\",\n",
            "                    \"yt_views\": 1498\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"Automated Inspection for rail cars using computer vision and machine learning\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=EzQLEea-4wU\",\n",
            "                    \"yt_views\": 1270\n",
            "                },\n",
            "                {\n",
            "                    \"talk_title\": \"Building a Conversation-focused LLM on Communication Data\",\n",
            "                    \"youtube_url\": \"https://www.youtube.com/watch?v=SIuTl5i-WEg\",\n",
            "                    \"yt_views\": 1245\n",
            "                }\n",
            "            ],\n",
            "            \"returned\": 10,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'entities': [{'talk_title': 'BloombergGPT: How we built a 50 billion parameter financial language model',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=m2Scj2SO85Y',\n",
              "     'yt_views': 127705},\n",
              "    {'talk_title': 'Quantifying the uncertainty in model predictions',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=-K8vDIyT3xY',\n",
              "     'yt_views': 4364},\n",
              "    {'talk_title': 'Building a Measurement System for Personalization: A Bayesian Approach',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=2DZogx96aR4',\n",
              "     'yt_views': 3755},\n",
              "    {'talk_title': 'Agentic AI: Unlocking Emergent Behavior in LLMs for Adaptive Workflow Automation',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=GwQi33fmexU',\n",
              "     'yt_views': 2372},\n",
              "    {'talk_title': 'Making ChatGPT funny with Prompt Optimization',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=lo6OOTlSS6A',\n",
              "     'yt_views': 2279},\n",
              "    {'talk_title': 'How many Labelled Examples do you need for a BERT-sized Model to Beat GPT4 on Predictive Tasks?',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=3iaxLTKJROc',\n",
              "     'yt_views': 1873},\n",
              "    {'talk_title': 'LLMs for Leaders & Senior Product Managers',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=RJawFx4kSMM',\n",
              "     'yt_views': 1666},\n",
              "    {'talk_title': 'Learn Your Codebase: Fine-tuning CodeLlama with Flyte… to Learn Flyte',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=VjIVPmow31A',\n",
              "     'yt_views': 1498},\n",
              "    {'talk_title': 'Automated Inspection for rail cars using computer vision and machine learning',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=EzQLEea-4wU',\n",
              "     'yt_views': 1270},\n",
              "    {'talk_title': 'Building a Conversation-focused LLM on Communication Data',\n",
              "     'youtube_url': 'https://www.youtube.com/watch?v=SIuTl5i-WEg',\n",
              "     'yt_views': 1245}],\n",
              "   'returned': 10,\n",
              "   'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Aggregate sanity on views\n",
        "\n",
        "Min/Max/Average quickly surface outliers."
      ],
      "metadata": {
        "id": "A17-2M1yUygc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([{\n",
        "  \"FindEntity\": {\n",
        "    \"with_class\": \"Talk\",\n",
        "    \"results\": {\n",
        "      \"min\": \"yt_views\",\n",
        "      \"max\": \"yt_views\",\n",
        "      \"average\": \"yt_views\"\n",
        "    }\n",
        "  }\n",
        "}])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDjAqO37Uvhp",
        "outputId": "30570f77-3a9e-46d8-8db1-acb8f96e1295"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"_avg\": {\n",
            "                \"yt_views\": 693.205035971223\n",
            "            },\n",
            "            \"returned\": 0,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'_avg': {'yt_views': 693.205035971223},\n",
              "   'returned': 0,\n",
              "   'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Filter by speaker name (exact match)\n",
        "\n",
        "oops - we have multiple speakers for a single talk :("
      ],
      "metadata": {
        "id": "jfRjRImGU2H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([{\n",
        "  \"FindEntity\": {\n",
        "    \"with_class\": \"Talk\",\n",
        "    \"constraints\": { \"speaker_name\": [\"==\", \"Michael Haacke Concha\"] },\n",
        "    \"results\": { \"list\": [\"talk_title\", \"event_name\", \"yt_published_at\"] },\n",
        "    \"sort\": { \"key\": \"yt_published_at\", \"order\": \"descending\" },\n",
        "    \"limit\": 20\n",
        "  }\n",
        "}])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgNyjg4bU0jV",
        "outputId": "027b52bf-b948-4d0e-8a61-6fd08e2c1011"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"returned\": 0,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'returned': 0, 'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## speaker class addition\n",
        "to cater to multiple speakers for same talk (above query issue)"
      ],
      "metadata": {
        "id": "ooe0KflpYwFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same CSV\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df = df[df[\"Talk Title\"].notna()].copy().reset_index(drop=True)\n",
        "df = df.loc[:, ~df.columns.duplicated()].copy()\n",
        "\n",
        "PERSON_CLASS = \"Person\"\n",
        "EDGE_CLASS   = \"TalkHasSpeaker\"\n",
        "TALK_CLASS   = \"Talk\"\n"
      ],
      "metadata": {
        "id": "ZVsZ145XWz-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_speakers(csv_str):\n",
        "    if pd.isna(csv_str) or not str(csv_str).strip():\n",
        "        return []\n",
        "    # split on comma, trim whitespace, drop empties\n",
        "    return [s.strip() for s in str(csv_str).split(\",\") if s.strip()]\n",
        "\n",
        "# We already created deterministic talk_id when ingesting Talks.\n",
        "# We can simply read it back from DB. Since we didn't store talk_id in CSV, we’ll find Talk by title.\n",
        "# (titles are unique.)\n",
        "def talk_ref_cmd_by_title(talk_title, ref_id):\n",
        "    return {\n",
        "        \"FindEntity\": {\n",
        "            \"with_class\": TALK_CLASS,\n",
        "            \"_ref\": ref_id,\n",
        "            \"unique\": True,\n",
        "            \"constraints\": {\"talk_title\": [\"==\", talk_title]},\n",
        "            \"results\": {\"list\": [\"talk_id\"]}  # handy for debugging\n",
        "        }\n",
        "    }\n",
        "\n",
        "class SpeakerEdgesGenerator:\n",
        "    \"\"\"\n",
        "    For each row:\n",
        "      1) Find Talk by talk_title (unique)\n",
        "      2) For each speaker name:\n",
        "           - AddEntity Person if_not_found by name\n",
        "           - AddConnection TalkHasSpeaker (src=talk, dst=person) with if_not_found\n",
        "    Returns many commands per row; no blobs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame):\n",
        "        self.df = dataframe\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx_or_slice):\n",
        "        if isinstance(idx_or_slice, int):\n",
        "            return self._row_to_cmds(idx_or_slice)\n",
        "        if isinstance(idx_or_slice, slice):\n",
        "            out = []\n",
        "            start = idx_or_slice.start or 0\n",
        "            stop  = idx_or_slice.stop  or len(self.df)\n",
        "            step  = idx_or_slice.step  or 1\n",
        "            for i in range(start, min(stop, len(self.df)), step):\n",
        "                out.append(self._row_to_cmds(i))\n",
        "            return out\n",
        "        try:\n",
        "            indices = list(idx_or_slice)\n",
        "            return [self._row_to_cmds(int(i)) for i in indices]\n",
        "        except Exception:\n",
        "            return self._row_to_cmds(int(idx_or_slice))\n",
        "\n",
        "    def get_indices(self):\n",
        "        # index Person.name for fast upserts + optional Talk.talk_title (we use it to find Talk)\n",
        "        return {\n",
        "            \"entity\": {\n",
        "                PERSON_CLASS: [\"name\"],\n",
        "                TALK_CLASS:   [\"talk_title\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _row_to_cmds(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        talk_title = str(r.get(\"Talk Title\")).strip() if pd.notna(r.get(\"Talk Title\")) else None\n",
        "        speakers   = split_speakers(r.get(\"Full Name\"))\n",
        "\n",
        "        if not talk_title or not speakers:\n",
        "            # nothing to do for this row\n",
        "            return [], []\n",
        "\n",
        "        cmds = []\n",
        "        blobs = []\n",
        "\n",
        "        # 1) find the talk by title\n",
        "        cmds.append(talk_ref_cmd_by_title(talk_title, ref_id=1))\n",
        "\n",
        "        # 2) for each speaker: AddEntity Person (if_not_found) + AddConnection TalkHasSpeaker\n",
        "        ref_counter = 2\n",
        "        for name in speakers:\n",
        "            # AddEntity Person\n",
        "            cmds.append({\n",
        "                \"AddEntity\": {\n",
        "                    \"class\": PERSON_CLASS,\n",
        "                    \"_ref\": ref_counter,\n",
        "                    \"if_not_found\": {\"name\": [\"==\", name]},\n",
        "                    \"properties\": {\"name\": name}\n",
        "                }\n",
        "            })\n",
        "            # AddConnection TalkHasSpeaker (Talk -> Person)\n",
        "            # using separate AddConnection; it supports if_not_found\n",
        "            cmds.append({\n",
        "                \"AddConnection\": {\n",
        "                    \"class\": EDGE_CLASS,\n",
        "                    \"src\": 1,              # Talk ref\n",
        "                    \"dst\": ref_counter,    # Person ref\n",
        "                    \"if_not_found\": {}     # create only if missing\n",
        "                }\n",
        "            })\n",
        "            ref_counter += 1\n",
        "\n",
        "        return cmds, blobs"
      ],
      "metadata": {
        "id": "SM4eF9mJYVZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = SpeakerEdgesGenerator(df)\n",
        "\n",
        "# Auto-create indices Person.name and Talk.talk_title (fast and convenient)\n",
        "loader.query_setup(gen)  # uses get_indices()\n",
        "# Run in parallel\n",
        "loader.ingest(gen, batchsize=25, numthreads=8, stats=True)\n",
        "print(\"Done linking speakers.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e21WYd64YkI4",
        "outputId": "124985ae-2bac-4c69-a124-ba645cadd6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aperturedb.Connector:Connection broken. Reconnecting attempt [1/3] .. PID = 1241\n",
            "Progress: 100%|██████████| 278/278 [00:03<00:00, 91.7items/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============ ApertureDB Loader Stats ============\n",
            "Total time (s): 3.0314011573791504\n",
            "Total queries executed: 16\n",
            "Avg Query time (s): 0.9772580116987228\n",
            "Query time std: 0.6979733340649226\n",
            "Avg Query Throughput (q/s): 8.186169777307803\n",
            "Overall insertion throughput (element/s): 91.70676712426594\n",
            "Total inserted elements: 278\n",
            "Total successful commands: 1024\n",
            "=================================================\n",
            "Done linking speakers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find talks by a specific person (exact full name):"
      ],
      "metadata": {
        "id": "ezPzTk5pZC8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([\n",
        "  { \"FindEntity\": {\n",
        "      \"with_class\": \"Person\",\n",
        "      \"_ref\": 1,\n",
        "      \"unique\": True,\n",
        "      \"constraints\": {\"name\": [\"==\", \"Michael Haacke Concha\"]}\n",
        "  }},\n",
        "  { \"FindEntity\": {\n",
        "      \"with_class\": \"Talk\",\n",
        "      \"is_connected_to\": {\n",
        "        \"ref\": 1,\n",
        "        \"direction\": \"in\",\n",
        "        \"connection_class\": \"TalkHasSpeaker\"\n",
        "      },\n",
        "      \"results\": {\"list\": [\"talk_title\", \"speaker_name\", \"event_name\", \"yt_published_at\"]},\n",
        "      \"sort\": {\"key\": \"yt_published_at\", \"order\": \"descending\"},\n",
        "      \"limit\": 20\n",
        "  }}\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrawGKFRVTag",
        "outputId": "37497fd9-ede0-472a-de2a-e99800107b6a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"returned\": 0,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"entities\": [\n",
            "                {\n",
            "                    \"event_name\": \"MLOps & GenAI World 2024\",\n",
            "                    \"speaker_name\": \"Michael Haacke Concha, Diego Castillo Warnken\",\n",
            "                    \"talk_title\": \"Revolutionizing the skies: Mlops case study of LATAM airlines\",\n",
            "                    \"yt_published_at\": {\n",
            "                        \"_date\": \"2024-12-11T00:00:00+00:00\"\n",
            "                    }\n",
            "                }\n",
            "            ],\n",
            "            \"returned\": 1,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'returned': 0, 'status': 0}},\n",
              " {'FindEntity': {'entities': [{'event_name': 'MLOps & GenAI World 2024',\n",
              "     'speaker_name': 'Michael Haacke Concha, Diego Castillo Warnken',\n",
              "     'talk_title': 'Revolutionizing the skies: Mlops case study of LATAM airlines',\n",
              "     'yt_published_at': {'_date': '2024-12-11T00:00:00+00:00'}}],\n",
              "   'returned': 1,\n",
              "   'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List all speakers for a given talk title:"
      ],
      "metadata": {
        "id": "LQn3rdQHZD4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([\n",
        "  { \"FindEntity\": {\n",
        "      \"with_class\": \"Talk\",\n",
        "      \"_ref\": 1,\n",
        "      \"unique\": True,\n",
        "      \"constraints\": {\"talk_title\": [\"==\", \"From ML Repository to ML Production Pipeline\"]}\n",
        "  }},\n",
        "  { \"FindEntity\": {\n",
        "      \"with_class\": \"Person\",\n",
        "      \"is_connected_to\": {\n",
        "        \"ref\": 1,\n",
        "        \"direction\": \"out\",\n",
        "        \"connection_class\": \"TalkHasSpeaker\"\n",
        "      },\n",
        "      \"results\": {\"list\": [\"name\"]},\n",
        "      \"sort\": \"name\"\n",
        "  }}\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph_LodIfY0-n",
        "outputId": "5bf97fb9-4ca0-4e3f-f4a4-b3846645b4d3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"returned\": 0,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"FindEntity\": {\n",
            "            \"entities\": [\n",
            "                {\n",
            "                    \"name\": \"Dariusz Adamczyk\"\n",
            "                },\n",
            "                {\n",
            "                    \"name\": \"Jakub Witkowski\"\n",
            "                }\n",
            "            ],\n",
            "            \"returned\": 2,\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'FindEntity': {'returned': 0, 'status': 0}},\n",
              " {'FindEntity': {'entities': [{'name': 'Dariusz Adamczyk'},\n",
              "    {'name': 'Jakub Witkowski'}],\n",
              "   'returned': 2,\n",
              "   'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get full schema"
      ],
      "metadata": {
        "id": "1p2MaFrbbbfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run([\n",
        "  { \"GetSchema\": { } }\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQfxqW0VZGhC",
        "outputId": "5210a0b0-d34b-48f3-c11a-f3d8bbaeb242"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"GetSchema\": {\n",
            "            \"connections\": {\n",
            "                \"classes\": {\n",
            "                    \"TalkHasSpeaker\": {\n",
            "                        \"dst\": \"Person\",\n",
            "                        \"matched\": 373,\n",
            "                        \"properties\": null,\n",
            "                        \"src\": \"Talk\"\n",
            "                    }\n",
            "                },\n",
            "                \"returned\": 1\n",
            "            },\n",
            "            \"entities\": {\n",
            "                \"classes\": {\n",
            "                    \"Person\": {\n",
            "                        \"matched\": 338,\n",
            "                        \"properties\": {\n",
            "                            \"name\": [\n",
            "                                338,\n",
            "                                true,\n",
            "                                \"String\"\n",
            "                            ]\n",
            "                        }\n",
            "                    },\n",
            "                    \"Talk\": {\n",
            "                        \"matched\": 278,\n",
            "                        \"properties\": {\n",
            "                            \"abstract\": [\n",
            "                                274,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"bio\": [\n",
            "                                269,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"category_primary\": [\n",
            "                                277,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"company_name\": [\n",
            "                                278,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"event_name\": [\n",
            "                                242,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"industries\": [\n",
            "                                157,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"job_title\": [\n",
            "                                278,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"keywords_csv\": [\n",
            "                                232,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"prereq_knowledge\": [\n",
            "                                46,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"speaker_name\": [\n",
            "                                278,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"talk_id\": [\n",
            "                                278,\n",
            "                                true,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"talk_title\": [\n",
            "                                278,\n",
            "                                true,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"tech_level\": [\n",
            "                                238,\n",
            "                                false,\n",
            "                                \"Number\"\n",
            "                            ],\n",
            "                            \"track\": [\n",
            "                                261,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"unique_session_note\": [\n",
            "                                108,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"what_youll_learn\": [\n",
            "                                218,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"youtube_id\": [\n",
            "                                278,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"youtube_url\": [\n",
            "                                278,\n",
            "                                false,\n",
            "                                \"String\"\n",
            "                            ],\n",
            "                            \"yt_published_at\": [\n",
            "                                274,\n",
            "                                false,\n",
            "                                \"Datetime\"\n",
            "                            ],\n",
            "                            \"yt_views\": [\n",
            "                                278,\n",
            "                                false,\n",
            "                                \"Number\"\n",
            "                            ]\n",
            "                        }\n",
            "                    }\n",
            "                },\n",
            "                \"returned\": 2\n",
            "            },\n",
            "            \"refreshed\": \"2025-09-27T23:02:16.563962Z\",\n",
            "            \"status\": 0\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'GetSchema': {'connections': {'classes': {'TalkHasSpeaker': {'dst': 'Person',\n",
              "      'matched': 373,\n",
              "      'properties': None,\n",
              "      'src': 'Talk'}},\n",
              "    'returned': 1},\n",
              "   'entities': {'classes': {'Person': {'matched': 338,\n",
              "      'properties': {'name': [338, True, 'String']}},\n",
              "     'Talk': {'matched': 278,\n",
              "      'properties': {'abstract': [274, False, 'String'],\n",
              "       'bio': [269, False, 'String'],\n",
              "       'category_primary': [277, False, 'String'],\n",
              "       'company_name': [278, False, 'String'],\n",
              "       'event_name': [242, False, 'String'],\n",
              "       'industries': [157, False, 'String'],\n",
              "       'job_title': [278, False, 'String'],\n",
              "       'keywords_csv': [232, False, 'String'],\n",
              "       'prereq_knowledge': [46, False, 'String'],\n",
              "       'speaker_name': [278, False, 'String'],\n",
              "       'talk_id': [278, True, 'String'],\n",
              "       'talk_title': [278, True, 'String'],\n",
              "       'tech_level': [238, False, 'Number'],\n",
              "       'track': [261, False, 'String'],\n",
              "       'unique_session_note': [108, False, 'String'],\n",
              "       'what_youll_learn': [218, False, 'String'],\n",
              "       'youtube_id': [278, False, 'String'],\n",
              "       'youtube_url': [278, False, 'String'],\n",
              "       'yt_published_at': [274, False, 'Datetime'],\n",
              "       'yt_views': [278, False, 'Number']}}},\n",
              "    'returned': 2},\n",
              "   'refreshed': '2025-09-27T23:02:16.563962Z',\n",
              "   'status': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7NyroHJaalE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}