{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4177a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All tools imported successfully!\n",
      "ðŸ”‘ ApertureDB Key configured: Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import required libraries and tools\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Add tools directory to path\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import all our tools\n",
    "from search_talks_by_filters import search_talks_by_filters\n",
    "from search_talks_semantically import search_talks_semantically\n",
    "from analyze_speaker_activity import analyze_speaker_activity\n",
    "from get_talk_details import get_talk_details\n",
    "from find_similar_content import find_similar_content\n",
    "from analyze_topics_and_trends import analyze_topics_and_trends\n",
    "\n",
    "print(\"âœ… All tools imported successfully!\")\n",
    "print(f\"ðŸ”‘ ApertureDB Key configured: {'Yes' if os.getenv('APERTUREDB_KEY') else 'No'}\")\n",
    "\n",
    "# Helper function for pretty printing results\n",
    "def print_results(result, max_results=5):\n",
    "    \"\"\"Pretty print tool results with truncation\"\"\"\n",
    "    if isinstance(result, dict) and 'results' in result:\n",
    "        print(f\"Total found: {result.get('total_found', 'Unknown')}\")\n",
    "        if result.get('query_summary'):\n",
    "            print(f\"Query: {result['query_summary']}\")\n",
    "        if result.get('sort_info'):\n",
    "            print(f\"Sorting: {result['sort_info']}\")\n",
    "        \n",
    "        results = result['results'][:max_results]\n",
    "        for i, talk in enumerate(results, 1):\n",
    "            print(f\"\\n{i}. {talk.get('title', 'No Title')}\")\n",
    "            print(f\"   Speaker: {talk.get('speaker', 'Unknown')}\")\n",
    "            print(f\"   Company: {talk.get('company', 'Unknown')}\")\n",
    "            print(f\"   Views: {talk.get('views', 0):,}\")\n",
    "            if talk.get('published_date'):\n",
    "                print(f\"   Date: {talk['published_date']}\")\n",
    "    else:\n",
    "        pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350443c",
   "metadata": {},
   "source": [
    "# Test Scenarios for analyze_topics_and_trends Tool\n",
    "\n",
    "This notebook contains comprehensive test scenarios for the `analyze_topics_and_trends` tool:\n",
    "\n",
    "**Analysis Types Covered:**\n",
    "1. **Tools Analysis** - Software tools and libraries (Tests 1, 4, 8, 12)\n",
    "2. **Technology Analysis** - Technologies and tech concepts (Tests 2, 6, 9, 11)  \n",
    "3. **Topic Analysis** - Discussion themes and patterns (Tests 3, 7)\n",
    "4. **Keyword Analysis** - Frequent terms and vocabulary (Tests 5, 10)\n",
    "\n",
    "**Filter Dimensions Tested:**\n",
    "- **Time-based**: Recent years (2023-2024), Historical (2020-2022), Single year (2023), Current (2024)\n",
    "- **Category-based**: Deployment & Integration, MLOps, Business & Stakeholder Alignment\n",
    "- **Event-based**: MLOps & GenAI World 2024\n",
    "- **Content Source**: Transcripts only, Abstracts only, All sources combined\n",
    "- **Threshold-based**: Different minimum mention requirements (2, 3, 4, 10+)\n",
    "\n",
    "Each test demonstrates realistic scenarios where users would want to understand trends, popular tools, emerging technologies, or topic evolution over time within the MLOps ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893da1ca",
   "metadata": {},
   "source": [
    "### Test 1: Analyze Top Software Tools Mentioned Across All Content\n",
    "\n",
    "**Scenario**: User wants to understand which software tools and libraries are most frequently discussed in MLOps presentations  \n",
    "**Query**: \"What are the most popular software tools mentioned in all talks?\"\n",
    "\n",
    "This test analyzes tool mentions across all content to identify the most frequently referenced software libraries, frameworks, and platforms. The tool uses pattern matching to identify tools like TensorFlow, PyTorch, Docker, Kubernetes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45826dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top Software Tools Analysis ===\n",
      "{'analysis_results': [{'item': 'kubernetes', 'count': 21, 'percentage': 7.6, 'sample_mentions': [{'talk_title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'published_date': '2024-12-05'}, {'talk_title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'published_date': '2024-12-05'}, {'talk_title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'published_date': '2024-12-05'}]}, {'item': 'langchain', 'count': 20, 'percentage': 7.2, 'sample_mentions': [{'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}]}, {'item': 'pytorch', 'count': 19, 'percentage': 6.8, 'sample_mentions': [{'talk_title': 'Extending PyTorch for Custom Compiler Targets', 'published_date': '2024-10-31'}, {'talk_title': 'Extending PyTorch for Custom Compiler Targets', 'published_date': '2024-10-31'}, {'talk_title': 'Extending PyTorch for Custom Compiler Targets', 'published_date': '2024-10-31'}]}, {'item': 'langgraph', 'count': 17, 'percentage': 6.1, 'sample_mentions': [{'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}]}, {'item': 'openai', 'count': 11, 'percentage': 4.0, 'sample_mentions': [{'talk_title': 'LLM economics : The Cost of leveraging Large Language Models', 'published_date': '2024-05-15'}, {'talk_title': 'LLM economics : The Cost of leveraging Large Language Models', 'published_date': '2024-05-15'}, {'talk_title': 'LLM economics : The Cost of leveraging Large Language Models', 'published_date': '2024-05-15'}]}, {'item': 'transformers', 'count': 10, 'percentage': 3.6, 'sample_mentions': [{'talk_title': 'Building AI Applications with Transformers', 'published_date': '2023-08-17'}, {'talk_title': 'Building AI Applications with Transformers', 'published_date': '2023-08-17'}, {'talk_title': 'Assessing Alignment of Climate Disclosures Using NLP for the Financial Markets', 'published_date': None}]}, {'item': 'github', 'count': 7, 'percentage': 2.5, 'sample_mentions': [{'talk_title': 'Leveraging Large Language Models to build Enterprise AI', 'published_date': '2024-10-31'}, {'talk_title': 'Building AI Applications with Transformers', 'published_date': '2023-08-17'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}]}, {'item': 'hugging face', 'count': 6, 'percentage': 2.2, 'sample_mentions': [{'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}, {'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}, {'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}]}, {'item': 'jupyter', 'count': 5, 'percentage': 1.8, 'sample_mentions': [{'talk_title': 'Operationalizing data-centric AI: Practical algorithms + software to quickly improve ML datasets', 'published_date': '2023-11-02'}, {'talk_title': 'From Chaos to Control: Mastering ML Reproducibility at scale', 'published_date': '2024-10-31'}, {'talk_title': 'Evaluation Techniques for Large Language Models', 'published_date': '2024-05-15'}]}, {'item': 'weights & biases', 'count': 5, 'percentage': 1.8, 'sample_mentions': [{'talk_title': 'Hemm: Holistic Evaluation of Multi-modal Generative Models', 'published_date': '2024-12-05'}, {'talk_title': 'Hemm: Holistic Evaluation of Multi-modal Generative Models', 'published_date': '2024-12-05'}, {'talk_title': 'Hemm: Holistic Evaluation of Multi-modal Generative Models', 'published_date': '2024-12-05'}]}, {'item': 'redis', 'count': 4, 'percentage': 1.4, 'sample_mentions': [{'talk_title': 'Building a Fraud Detection Model with Feature Stores (Includes Bonus Case Study: How Shopify uses Feast to Manage its ML Features)', 'published_date': '2023-08-17'}, {'talk_title': 'Feature Stores in Practice: Train and Deploy an End-to-End Fraud Detection Model with Featureform, Redis, and AWS.', 'published_date': '2023-11-10'}, {'talk_title': 'Feature Stores in Practice: Train and Deploy an End-to-End Fraud Detection Model with Featureform, Redis, and AWS.', 'published_date': '2023-11-10'}]}, {'item': 'triton', 'count': 3, 'percentage': 1.1, 'sample_mentions': [{'talk_title': 'From Prototype to Product: Rapid iteration and ML model deployment at Dropbox', 'published_date': '2023-11-02'}, {'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}, {'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}]}, {'item': 'azure', 'count': 3, 'percentage': 1.1, 'sample_mentions': [{'talk_title': 'Revolutionizing Cloud Storage: From Petabytes to Intelligence', 'published_date': '2024-12-09'}, {'talk_title': 'Revolutionizing Cloud Storage: From Petabytes to Intelligence', 'published_date': '2024-12-09'}, {'talk_title': 'Demystifying Multi-Agent Patterns', 'published_date': '2024-12-08'}]}], 'time_trends': {}, 'analysis_summary': 'Performed tools analysis from talk abstracts/metadata', 'total_items_found': 13, 'content_stats': {'total_talks': 278, 'total_text_chunks': 278, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Analyze Top Software Tools\n",
    "result1 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"tools\",\n",
    "    \"top_n\": 15,\n",
    "    \"min_mentions\": 3\n",
    "})\n",
    "print(\"=== Top Software Tools Analysis ===\")\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09b6d2",
   "metadata": {},
   "source": [
    "### Test 2: Technology Trends in Recent Years (2023-2024)\n",
    "\n",
    "**Scenario**: User wants to understand which technologies are trending in recent MLOps discussions  \n",
    "**Query**: \"What technologies are most discussed in talks from 2023-2024?\"\n",
    "\n",
    "This test focuses on technology mentions (AI, ML, LLMs, Vector Databases, etc.) from recent years to identify current technological focus areas and emerging trends in the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50223ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Recent Technology Trends ===\n",
      "{'analysis_results': [{'item': 'AI', 'count': 612, 'percentage': 225.0}, {'item': 'ML', 'count': 399, 'percentage': 146.7}, {'item': 'MLOps', 'count': 160, 'percentage': 58.8}, {'item': 'LLM', 'count': 151, 'percentage': 55.5}, {'item': 'machine learning', 'count': 105, 'percentage': 38.6}, {'item': 'RAG', 'count': 94, 'percentage': 34.6}, {'item': 'Machine Learning', 'count': 53, 'percentage': 19.5}, {'item': 'cloud', 'count': 37, 'percentage': 13.6}, {'item': 'real-time', 'count': 33, 'percentage': 12.1}, {'item': 'monitoring', 'count': 32, 'percentage': 11.8}, {'item': 'deep learning', 'count': 17, 'percentage': 6.2}, {'item': 'GPT', 'count': 14, 'percentage': 5.1}], 'time_trends': {}, 'analysis_summary': 'Performed technologies analysis filtered by from 2023-01-01, until 2024-12-31 from talk abstracts/metadata', 'total_items_found': 12, 'content_stats': {'total_talks': 272, 'total_text_chunks': 272, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Recent Technology Trends (2023-2024)\n",
    "result2 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"technologies\",\n",
    "    \"date_from\": \"2023-01-01\",\n",
    "    \"date_to\": \"2024-12-31\",\n",
    "    \"top_n\": 12\n",
    "})\n",
    "print(\"=== Recent Technology Trends ===\")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea8bbc",
   "metadata": {},
   "source": [
    "### Test 3: Topic Analysis from Video Transcripts\n",
    "\n",
    "**Scenario**: User wants to analyze what topics are actually discussed in video content rather than just abstracts  \n",
    "**Query**: \"What are the main discussion topics based on actual video transcripts?\"\n",
    "\n",
    "This test analyzes topics from video transcripts to understand what speakers actually talk about during their presentations, which may differ from abstract summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c5753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Topics from Video Transcripts ===\n",
      "{'analysis_results': [{'item': 'data', 'count': 11854, 'percentage': 70.7}, {'item': 'model', 'count': 10440, 'percentage': 62.3}, {'item': 'training', 'count': 2192, 'percentage': 13.1}, {'item': 'pipeline', 'count': 1588, 'percentage': 9.5}, {'item': 'production', 'count': 1219, 'percentage': 7.3}, {'item': 'feature', 'count': 1157, 'percentage': 6.9}, {'item': 'agent', 'count': 1092, 'percentage': 6.5}, {'item': 'performance', 'count': 985, 'percentage': 5.9}, {'item': 'search', 'count': 968, 'percentage': 5.8}, {'item': 'vector', 'count': 881, 'percentage': 5.3}], 'time_trends': {}, 'analysis_summary': 'Performed topics analysis from video transcripts', 'total_items_found': 10, 'content_stats': {'total_talks': 278, 'total_text_chunks': 16770, 'content_sources': ['video transcripts']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Topic Analysis from Transcripts\n",
    "result3 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"topics\",\n",
    "    \"content_source\": \"transcripts\",\n",
    "    \"top_n\": 10,\n",
    "    \"min_mentions\": 5\n",
    "})\n",
    "print(\"=== Topics from Video Transcripts ===\")\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1446a",
   "metadata": {},
   "source": [
    "### Test 4: Tools Analysis for Deployment Category\n",
    "\n",
    "**Scenario**: User wants to know which tools are most mentioned in deployment-focused talks  \n",
    "**Query**: \"What tools are most discussed in deployment and integration talks?\"\n",
    "\n",
    "This test filters content to the \"Deployment and integration\" category and analyzes tool mentions to understand the technology stack commonly used for deployment scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb7dca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tools in Deployment & Integration ===\n",
      "{'analysis_results': [{'item': 'kubernetes', 'count': 18, 'percentage': 27.7, 'sample_mentions': [{'talk_title': 'Deploying LLMs on Kubernetes environments', 'published_date': '2024-10-31'}, {'talk_title': 'Deploying LLMs on Kubernetes environments', 'published_date': '2024-10-31'}, {'talk_title': 'Deploying LLMs on Kubernetes environments', 'published_date': '2024-10-31'}]}, {'item': 'redis', 'count': 4, 'percentage': 6.2, 'sample_mentions': [{'talk_title': 'Building a Fraud Detection Model with Feature Stores (Includes Bonus Case Study: How Shopify uses Feast to Manage its ML Features)', 'published_date': '2023-08-17'}, {'talk_title': 'Feature Stores in Practice: Train and Deploy an End-to-End Fraud Detection Model with Featureform, Redis, and AWS.', 'published_date': '2023-11-10'}, {'talk_title': 'Feature Stores in Practice: Train and Deploy an End-to-End Fraud Detection Model with Featureform, Redis, and AWS.', 'published_date': '2023-11-10'}]}, {'item': 'triton', 'count': 3, 'percentage': 4.6, 'sample_mentions': [{'talk_title': 'From Prototype to Product: Rapid iteration and ML model deployment at Dropbox', 'published_date': '2023-11-02'}, {'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}, {'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}]}, {'item': 'openai', 'count': 3, 'percentage': 4.6, 'sample_mentions': [{'talk_title': \"Building an end-to-end web application integrated with Microsoft's Semantic Kernel and a Large Language Model\", 'published_date': '2023-08-17'}, {'talk_title': \"Building an end-to-end web application integrated with Microsoft's Semantic Kernel and a Large Language Model\", 'published_date': '2023-08-17'}, {'talk_title': 'Creating our own private OpenAI API', 'published_date': '2024-12-08'}]}, {'item': 'azure', 'count': 3, 'percentage': 4.6, 'sample_mentions': [{'talk_title': 'Revolutionizing Cloud Storage: From Petabytes to Intelligence', 'published_date': '2024-12-09'}, {'talk_title': 'Revolutionizing Cloud Storage: From Petabytes to Intelligence', 'published_date': '2024-12-09'}, {'talk_title': 'Demystifying Multi-Agent Patterns', 'published_date': '2024-12-08'}]}, {'item': 'aws', 'count': 2, 'percentage': 3.1, 'sample_mentions': [{'talk_title': 'Building a Fraud Detection Model with Feature Stores (Includes Bonus Case Study: How Shopify uses Feast to Manage its ML Features)', 'published_date': '2023-08-17'}, {'talk_title': 'Feature Stores in Practice: Train and Deploy an End-to-End Fraud Detection Model with Featureform, Redis, and AWS.', 'published_date': '2023-11-10'}]}, {'item': 'kafka', 'count': 2, 'percentage': 3.1, 'sample_mentions': [{'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}, {'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}]}, {'item': 'prometheus', 'count': 2, 'percentage': 3.1, 'sample_mentions': [{'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}, {'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}]}, {'item': 'grafana', 'count': 2, 'percentage': 3.1, 'sample_mentions': [{'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}, {'talk_title': 'Production ML Serving & Monitoring in Kubernetes', 'published_date': '2023-11-02'}]}], 'time_trends': {}, 'analysis_summary': \"Performed tools analysis filtered by category 'Deployment and integration' from talk abstracts/metadata\", 'total_items_found': 9, 'content_stats': {'total_talks': 65, 'total_text_chunks': 65, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Tools in Deployment Category\n",
    "result4 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"tools\",\n",
    "    \"category\": \"Deployment and integration\",\n",
    "    \"top_n\": 10\n",
    "})\n",
    "print(\"=== Tools in Deployment & Integration ===\")\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72adbd",
   "metadata": {},
   "source": [
    "### Test 5: Keyword Analysis from MLOps & GenAI World 2024\n",
    "\n",
    "**Scenario**: User wants to analyze the most frequently used keywords in a specific event  \n",
    "**Query**: \"What were the most common keywords in MLOps & GenAI World 2024?\"\n",
    "\n",
    "This test performs keyword frequency analysis on content from a specific event to understand the terminology and focus areas of that particular conference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d454bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Keywords from MLOps & GenAI World 2024 ===\n",
      "{'analysis_results': [{'item': 'models', 'count': 117, 'percentage': 0.83}, {'item': 'model', 'count': 85, 'percentage': 0.6}, {'item': 'data', 'count': 71, 'percentage': 0.5}, {'item': 'session', 'count': 70, 'percentage': 0.5}, {'item': 'systems', 'count': 67, 'percentage': 0.47}, {'item': 'llms', 'count': 62, 'percentage': 0.44}, {'item': 'applications', 'count': 61, 'percentage': 0.43}, {'item': 'generative', 'count': 55, 'percentage': 0.39}, {'item': 'llm', 'count': 55, 'percentage': 0.39}, {'item': 'deployment', 'count': 53, 'percentage': 0.38}, {'item': 'techniques', 'count': 49, 'percentage': 0.35}, {'item': 'open', 'count': 49, 'percentage': 0.35}, {'item': 'production', 'count': 48, 'percentage': 0.34}, {'item': 'challenges', 'count': 48, 'percentage': 0.34}, {'item': 'learn', 'count': 47, 'percentage': 0.33}, {'item': 'insights', 'count': 47, 'percentage': 0.33}, {'item': 'agent', 'count': 47, 'percentage': 0.33}, {'item': 'practical', 'count': 47, 'percentage': 0.33}, {'item': 'talk', 'count': 46, 'percentage': 0.33}, {'item': 'performance', 'count': 45, 'percentage': 0.32}], 'time_trends': {}, 'analysis_summary': \"Performed keywords analysis filtered by event 'MLOps & GenAI World 2024' from talk abstracts/metadata\", 'total_items_found': 20, 'content_stats': {'total_talks': 72, 'total_text_chunks': 72, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Keywords from MLOps & GenAI World 2024\n",
    "result5 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"keywords\",\n",
    "    \"event_name\": \"MLOps & GenAI World 2024\",\n",
    "    \"top_n\": 20,\n",
    "    \"min_mentions\": 4\n",
    "})\n",
    "print(\"=== Keywords from MLOps & GenAI World 2024 ===\")\n",
    "print(result5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a5772",
   "metadata": {},
   "source": [
    "### Test 6: Historical Technology Analysis (2020-2022)\n",
    "\n",
    "**Scenario**: User wants to understand how technology focus has evolved by looking at earlier years  \n",
    "**Query**: \"What technologies were most discussed in the early MLOps period (2020-2022)?\"\n",
    "\n",
    "This test analyzes technology mentions from earlier years to provide historical context and understand how the field has evolved over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031443ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Historical Technology Trends (2020-2022) ===\n",
      "{'analysis_results': [{'item': 'AI', 'count': 612, 'percentage': 225.0}, {'item': 'ML', 'count': 399, 'percentage': 146.7}, {'item': 'MLOps', 'count': 160, 'percentage': 58.8}, {'item': 'LLM', 'count': 151, 'percentage': 55.5}, {'item': 'machine learning', 'count': 105, 'percentage': 38.6}, {'item': 'RAG', 'count': 94, 'percentage': 34.6}, {'item': 'Machine Learning', 'count': 53, 'percentage': 19.5}, {'item': 'cloud', 'count': 37, 'percentage': 13.6}, {'item': 'real-time', 'count': 33, 'percentage': 12.1}, {'item': 'monitoring', 'count': 32, 'percentage': 11.8}], 'time_trends': {}, 'analysis_summary': 'Performed technologies analysis filtered by from 2020-01-01, until 2024-12-31 from talk abstracts/metadata', 'total_items_found': 10, 'content_stats': {'total_talks': 272, 'total_text_chunks': 272, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Historical Technology Analysis (2020-2022)\n",
    "result6 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"technologies\",\n",
    "    \"date_from\": \"2020-01-01\",\n",
    "    \"date_to\": \"2024-12-31\",\n",
    "    \"top_n\": 10\n",
    "})\n",
    "print(\"=== Historical Technology Trends (2020-2022) ===\")\n",
    "print(result6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c75eee",
   "metadata": {},
   "source": [
    "### Test 7: Comprehensive Analysis - All Content Sources\n",
    "\n",
    "**Scenario**: User wants the most complete view by analyzing both abstracts and transcripts together  \n",
    "**Query**: \"Give me a comprehensive view of all topics discussed across both abstracts and video content\"\n",
    "\n",
    "This test uses all available content sources (abstracts + transcripts) to provide the most comprehensive topic analysis possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd9468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comprehensive Topics Analysis (All Sources) ===\n",
      "{'analysis_results': [{'item': 'data', 'count': 12350, 'percentage': 72.4}, {'item': 'model', 'count': 10844, 'percentage': 63.6}, {'item': 'training', 'count': 2371, 'percentage': 13.9}, {'item': 'pipeline', 'count': 1646, 'percentage': 9.7}, {'item': 'production', 'count': 1342, 'percentage': 7.9}, {'item': 'feature', 'count': 1187, 'percentage': 7.0}, {'item': 'agent', 'count': 1149, 'percentage': 6.7}, {'item': 'performance', 'count': 1113, 'percentage': 6.5}, {'item': 'search', 'count': 1001, 'percentage': 5.9}, {'item': 'vector', 'count': 905, 'percentage': 5.3}, {'item': 'inference', 'count': 894, 'percentage': 5.2}, {'item': 'agents', 'count': 710, 'percentage': 4.2}, {'item': 'evaluation', 'count': 678, 'percentage': 4.0}, {'item': 'memory', 'count': 660, 'percentage': 3.9}, {'item': 'embedding', 'count': 612, 'percentage': 3.6}], 'time_trends': {}, 'analysis_summary': 'Performed topics analysis from abstracts and transcripts', 'total_items_found': 15, 'content_stats': {'total_talks': 278, 'total_text_chunks': 17048, 'content_sources': ['abstracts and transcripts']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 7: Comprehensive All-Content Analysis\n",
    "result7 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"topics\",\n",
    "    \"content_source\": \"all\",\n",
    "    \"top_n\": 15,\n",
    "    \"min_mentions\": 3\n",
    "})\n",
    "print(\"=== Comprehensive Topics Analysis (All Sources) ===\")\n",
    "print(result7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c195a",
   "metadata": {},
   "source": [
    "### Test 8: MLOps Category Tool Analysis\n",
    "\n",
    "**Scenario**: User wants to understand which tools are most important in core MLOps practices  \n",
    "**Query**: \"What are the essential tools mentioned in Introduction to MLOps and GenAI category talks?\"\n",
    "\n",
    "This test focuses specifically on the MLOps category to identify the core toolset and technologies that are central to MLOps and GenAI practices and workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09cb7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tools in MLOps Category ===\n",
      "{'analysis_results': [{'item': 'langchain', 'count': 7, 'percentage': 21.2, 'sample_mentions': [{'talk_title': 'Introduction to LangChain and Retrieval Augmented Generation (RAG)', 'published_date': '2023-11-02'}, {'talk_title': 'Introduction to LangChain and Retrieval Augmented Generation (RAG)', 'published_date': '2023-11-02'}, {'talk_title': 'Introduction to LangChain and Retrieval Augmented Generation (RAG)', 'published_date': '2023-11-02'}]}, {'item': 'transformers', 'count': 4, 'percentage': 12.1, 'sample_mentions': [{'talk_title': 'Building AI Applications with Transformers', 'published_date': '2023-08-17'}, {'talk_title': 'Building AI Applications with Transformers', 'published_date': '2023-08-17'}, {'talk_title': 'Transforming The Retail Industry with Transformers', 'published_date': '2023-08-17'}]}, {'item': 'mlflow', 'count': 2, 'percentage': 6.1, 'sample_mentions': [{'talk_title': 'Building Reproducible ML Processes with an Open Source Stack', 'published_date': '2024-10-31'}, {'talk_title': 'Building Reproducible ML Processes with an Open Source Stack', 'published_date': '2024-10-31'}]}], 'time_trends': {}, 'analysis_summary': \"Performed tools analysis filtered by category 'Introduction to MLOps and GenAI' from talk abstracts/metadata\", 'total_items_found': 3, 'content_stats': {'total_talks': 33, 'total_text_chunks': 33, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 8: MLOps Category Tools\n",
    "result8 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"tools\",\n",
    "    \"category\": \"Introduction to MLOps and GenAI\",\n",
    "    \"top_n\": 12,\n",
    "    \"min_mentions\": 2\n",
    "})\n",
    "print(\"=== Tools in MLOps Category ===\")\n",
    "print(result8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb77015a",
   "metadata": {},
   "source": [
    "### Test 9: Single Year Deep Dive - 2023 Technology Focus\n",
    "\n",
    "**Scenario**: User wants to understand the technology landscape for a specific year  \n",
    "**Query**: \"What were the key technologies and trends in 2023 specifically?\"\n",
    "\n",
    "This test performs a focused analysis on a single year (2023) to understand the technology landscape and trends during that specific period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c252cb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 2023 Technology Deep Dive ===\n",
      "{'analysis_results': [{'item': 'ML', 'count': 219, 'percentage': 178.0}, {'item': 'AI', 'count': 159, 'percentage': 129.3}, {'item': 'MLOps', 'count': 84, 'percentage': 68.3}, {'item': 'machine learning', 'count': 52, 'percentage': 42.3}, {'item': 'LLM', 'count': 36, 'percentage': 29.3}, {'item': 'Machine Learning', 'count': 28, 'percentage': 22.8}, {'item': 'monitoring', 'count': 18, 'percentage': 14.6}, {'item': 'deep learning', 'count': 11, 'percentage': 8.9}, {'item': 'Monitoring', 'count': 10, 'percentage': 8.1}, {'item': 'real-time', 'count': 9, 'percentage': 7.3}, {'item': 'cloud', 'count': 9, 'percentage': 7.3}, {'item': 'computer vision', 'count': 9, 'percentage': 7.3}, {'item': 'observability', 'count': 9, 'percentage': 7.3}, {'item': 'GPT', 'count': 8, 'percentage': 6.5}, {'item': 'NLP', 'count': 7, 'percentage': 5.7}], 'time_trends': {}, 'analysis_summary': 'Performed technologies analysis filtered by from 2023-01-01, until 2023-12-31 from talk abstracts/metadata', 'total_items_found': 15, 'content_stats': {'total_talks': 123, 'total_text_chunks': 123, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 9: 2023 Technology Deep Dive\n",
    "result9 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"technologies\",\n",
    "    \"date_from\": \"2023-01-01\",\n",
    "    \"date_to\": \"2023-12-31\",\n",
    "    \"top_n\": 15\n",
    "})\n",
    "print(\"=== 2023 Technology Deep Dive ===\")\n",
    "print(result9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf2ec4",
   "metadata": {},
   "source": [
    "### Test 10: High-Threshold Keywords Analysis\n",
    "\n",
    "**Scenario**: User wants to find only the most frequently mentioned keywords to avoid noise  \n",
    "**Query**: \"What are the most commonly used terms with at least 10 mentions?\"\n",
    "\n",
    "This test uses a higher minimum mention threshold to filter out rare terms and focus on the most significant and frequently used keywords across all content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9853b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Most Frequent Keywords (10+ mentions) ===\n",
      "{'analysis_results': [{'item': 'data', 'count': 496, 'percentage': 0.92}, {'item': 'models', 'count': 490, 'percentage': 0.91}, {'item': 'model', 'count': 404, 'percentage': 0.75}, {'item': 'llms', 'count': 266, 'percentage': 0.49}, {'item': 'learning', 'count': 257, 'percentage': 0.48}, {'item': 'our', 'count': 207, 'percentage': 0.38}, {'item': 'machine', 'count': 201, 'percentage': 0.37}, {'item': 'talk', 'count': 201, 'percentage': 0.37}, {'item': 'training', 'count': 179, 'percentage': 0.33}, {'item': 'challenges', 'count': 174, 'percentage': 0.32}, {'item': 'use', 'count': 173, 'percentage': 0.32}, {'item': 'applications', 'count': 165, 'percentage': 0.31}, {'item': 'mlops', 'count': 163, 'percentage': 0.3}, {'item': 'real', 'count': 162, 'percentage': 0.3}, {'item': 'generative', 'count': 162, 'percentage': 0.3}, {'item': 'systems', 'count': 160, 'percentage': 0.3}, {'item': 'llm', 'count': 153, 'percentage': 0.28}, {'item': 'language', 'count': 151, 'percentage': 0.28}, {'item': 'deployment', 'count': 150, 'percentage': 0.28}, {'item': 'business', 'count': 140, 'percentage': 0.26}, {'item': 'your', 'count': 138, 'percentage': 0.26}, {'item': 'learn', 'count': 130, 'percentage': 0.24}, {'item': 'using', 'count': 129, 'percentage': 0.24}, {'item': 'performance', 'count': 128, 'percentage': 0.24}, {'item': 'production', 'count': 123, 'percentage': 0.23}], 'time_trends': {}, 'analysis_summary': 'Performed keywords analysis from talk abstracts/metadata', 'total_items_found': 25, 'content_stats': {'total_talks': 278, 'total_text_chunks': 278, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 10: High-Threshold Keywords\n",
    "result10 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"keywords\",\n",
    "    \"min_mentions\": 10,\n",
    "    \"top_n\": 25\n",
    "})\n",
    "print(\"=== Most Frequent Keywords (10+ mentions) ===\")\n",
    "print(result10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725457b",
   "metadata": {},
   "source": [
    "### Test 11: Business Category Technology Analysis\n",
    "\n",
    "**Scenario**: User wants to understand technology discussed in business-focused talks  \n",
    "**Query**: \"What technologies are mentioned in business and stakeholder alignment talks?\"\n",
    "\n",
    "This test focuses on business-oriented content to understand which technologies are discussed in the context of business strategy and stakeholder concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "098f132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Technologies in Business Context ===\n",
      "{'analysis_results': [{'item': 'AI', 'count': 64, 'percentage': 220.7}, {'item': 'ML', 'count': 23, 'percentage': 79.3}, {'item': 'machine learning', 'count': 7, 'percentage': 24.1}, {'item': 'Machine Learning', 'count': 4, 'percentage': 13.8}, {'item': 'LLM', 'count': 4, 'percentage': 13.8}, {'item': 'Natural Language Processing', 'count': 2, 'percentage': 6.9}, {'item': 'MLOps', 'count': 2, 'percentage': 6.9}], 'time_trends': {}, 'analysis_summary': \"Performed technologies analysis filtered by category 'Business and stakeholder alignment' from talk abstracts/metadata\", 'total_items_found': 7, 'content_stats': {'total_talks': 29, 'total_text_chunks': 29, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 11: Business Category Technology Analysis\n",
    "result11 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"technologies\",\n",
    "    \"category\": \"Business and stakeholder alignment\",\n",
    "    \"top_n\": 8\n",
    "})\n",
    "print(\"=== Technologies in Business Context ===\")\n",
    "print(result11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47de8a",
   "metadata": {},
   "source": [
    "### Test 12: Recent Tools with Abstract Focus\n",
    "\n",
    "**Scenario**: User wants to understand which tools are highlighted in recent talk abstracts  \n",
    "**Query**: \"What tools are featured in abstracts of recent talks (2024)?\"\n",
    "\n",
    "This test focuses on recent abstracts to understand which tools are being highlighted as key components in current MLOps presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed8f9ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Recent Tools from 2024 Abstracts ===\n",
      "{'analysis_results': [{'item': 'pytorch', 'count': 17, 'percentage': 11.3, 'sample_mentions': [{'talk_title': 'Extending PyTorch for Custom Compiler Targets', 'published_date': '2024-10-31'}, {'talk_title': 'Extending PyTorch for Custom Compiler Targets', 'published_date': '2024-10-31'}, {'talk_title': 'Extending PyTorch for Custom Compiler Targets', 'published_date': '2024-10-31'}]}, {'item': 'langgraph', 'count': 17, 'percentage': 11.3, 'sample_mentions': [{'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}]}, {'item': 'kubernetes', 'count': 15, 'percentage': 9.9, 'sample_mentions': [{'talk_title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'published_date': '2024-12-05'}, {'talk_title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'published_date': '2024-12-05'}, {'talk_title': 'Leverage Kubernetes To Optimize the Utilization of Your AI Accelerators', 'published_date': '2024-12-05'}]}, {'item': 'langchain', 'count': 13, 'percentage': 8.6, 'sample_mentions': [{'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}]}, {'item': 'openai', 'count': 9, 'percentage': 6.0, 'sample_mentions': [{'talk_title': 'LLM economics : The Cost of leveraging Large Language Models', 'published_date': '2024-05-15'}, {'talk_title': 'LLM economics : The Cost of leveraging Large Language Models', 'published_date': '2024-05-15'}, {'talk_title': 'LLM economics : The Cost of leveraging Large Language Models', 'published_date': '2024-05-15'}]}, {'item': 'hugging face', 'count': 6, 'percentage': 4.0, 'sample_mentions': [{'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}, {'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}, {'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}]}, {'item': 'github', 'count': 5, 'percentage': 3.3, 'sample_mentions': [{'talk_title': 'Leveraging Large Language Models to build Enterprise AI', 'published_date': '2024-10-31'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph (Pt. 2)', 'published_date': '2024-12-06'}, {'talk_title': 'Building Agentic and Multi-Agent Systems with LangGraph', 'published_date': '2024-12-06'}]}, {'item': 'weights & biases', 'count': 5, 'percentage': 3.3, 'sample_mentions': [{'talk_title': 'Hemm: Holistic Evaluation of Multi-modal Generative Models', 'published_date': '2024-12-05'}, {'talk_title': 'Hemm: Holistic Evaluation of Multi-modal Generative Models', 'published_date': '2024-12-05'}, {'talk_title': 'Hemm: Holistic Evaluation of Multi-modal Generative Models', 'published_date': '2024-12-05'}]}, {'item': 'jupyter', 'count': 4, 'percentage': 2.6, 'sample_mentions': [{'talk_title': 'From Chaos to Control: Mastering ML Reproducibility at scale', 'published_date': '2024-10-31'}, {'talk_title': 'Evaluation Techniques for Large Language Models', 'published_date': '2024-05-15'}, {'talk_title': 'Uncertainty Quantification with Conformal Prediction: A Path to Reliable ML Models', 'published_date': '2024-10-31'}]}, {'item': 'azure', 'count': 3, 'percentage': 2.0, 'sample_mentions': [{'talk_title': 'Revolutionizing Cloud Storage: From Petabytes to Intelligence', 'published_date': '2024-12-09'}, {'talk_title': 'Revolutionizing Cloud Storage: From Petabytes to Intelligence', 'published_date': '2024-12-09'}, {'talk_title': 'Demystifying Multi-Agent Patterns', 'published_date': '2024-12-08'}]}, {'item': 'transformers', 'count': 3, 'percentage': 2.0, 'sample_mentions': [{'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}, {'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}, {'talk_title': 'Getting started with Generative Text and Fine-tuning LLMs in Hugging Face', 'published_date': '2024-10-31'}]}, {'item': 'anthropic', 'count': 2, 'percentage': 1.3, 'sample_mentions': [{'talk_title': 'LLM economics : The Cost of leveraging Large Language Models', 'published_date': '2024-05-15'}, {'talk_title': \"A Practitioner's Guide To Safeguarding Your LLM Applications\", 'published_date': '2024-10-31'}]}], 'time_trends': {}, 'analysis_summary': 'Performed tools analysis filtered by from 2024-01-01 from talk abstracts/metadata', 'total_items_found': 12, 'content_stats': {'total_talks': 151, 'total_text_chunks': 151, 'content_sources': ['talk abstracts/metadata']}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "# Test 12: Recent Tools from Abstracts (2024)\n",
    "result12 = analyze_topics_and_trends.invoke({\n",
    "    \"analysis_type\": \"tools\",\n",
    "    \"content_source\": \"abstracts\",\n",
    "    \"date_from\": \"2024-01-01\",\n",
    "    \"top_n\": 12\n",
    "})\n",
    "print(\"=== Recent Tools from 2024 Abstracts ===\")\n",
    "print(result12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
